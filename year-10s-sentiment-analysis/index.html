<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Year 10s: Sentiment Analysis - Headtilt</title><meta name="description" content="In 2019 I started up a programming-oriented Data Science class with my&hellip;"><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="https://headtilt.me/year-10s-sentiment-analysis/"><link rel="alternate" type="application/atom+xml" href="https://headtilt.me/feed.xml"><link rel="alternate" type="application/json" href="https://headtilt.me/feed.json"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@robpoulter"><meta name="twitter:title" content="Year 10s: Sentiment Analysis"><meta name="twitter:description" content="In 2019 I started up a programming-oriented Data Science class with my&hellip;"><meta name="twitter:image" content="https://headtilt.me/media/posts/77/2_sentiment_samples.png"><link rel="shortcut icon" href="https://headtilt.me/media/website/favicon.ico" type="image/x-icon"><link rel="preload" href="https://fonts.googleapis.com/css?family=Heebo:400,500|Playfair+Display:400" as="font" crossorigin><link rel="stylesheet" href="https://headtilt.me/assets/css/style.css?v=7aaef5a7341c740e40570fe5042e66fa"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://headtilt.me/year-10s-sentiment-analysis/"},"headline":"Year 10s: Sentiment Analysis","datePublished":"2019-12-29T15:46","dateModified":"2019-12-30T08:40","image":{"@type":"ImageObject","url":"https://headtilt.me/media/posts/77/2_sentiment_samples.png","height":310,"width":836},"description":"In 2019 I started up a programming-oriented Data Science class with my&hellip;","author":{"@type":"Person","name":"Rob"},"publisher":{"@type":"Organization","name":"Rob","logo":{"@type":"ImageObject","url":"https://headtilt.me/media/website/slice1.png","height":78,"width":354}}}</script><script async src="https://headtilt.me/assets/js/lazysizes.min.js?v=739e7d27e1cbc58b1b2e6882674b8867"></script><link rel="stylesheet" href="https://headtilt.me/assets/css/prism.css?v=718e86b555366857a48cea2de2ecf136"></head><body><div class="container"><header class="js-top"><a class="logo" href="https://headtilt.me/"><img src="https://headtilt.me/media/website/slice1.png" alt="Headtilt"></a><div class="top"><nav class="navbar js-navbar"><button class="navbar__toggle js-navbar__toggle" aria-expanded="false">Menu</button><ul class="navbar__menu"><li><a href="https://headtilt.me/wag/ramble/" target="_self">Ramble</a></li><li><a href="https://headtilt.me/wag/classroom/" target="_self">Classroom</a></li><li><a href="https://headtilt.me/About/" target="_self">About</a></li></ul></nav></div></header><main><article class="post u-wrapper"><header class="hero"><p class="post__meta">By <a href="https://headtilt.me/authors/rob/" rel="author" title="Rob">Rob</a> Published on <time datetime="2019-12-29T15:46">December 29, 2019</time></p><h1 class="post__title">Year 10s: Sentiment Analysis</h1></header><div class="post__featured-image post__image--normal"><img src="https://headtilt.me/media/posts/77/responsive/2_sentiment_samples-xs.png" data-srcset="https://headtilt.me/media/posts/77/responsive/2_sentiment_samples-xs.png 300w ,https://headtilt.me/media/posts/77/responsive/2_sentiment_samples-sm.png 480w ,https://headtilt.me/media/posts/77/responsive/2_sentiment_samples-md.png 768w ,https://headtilt.me/media/posts/77/responsive/2_sentiment_samples-lg.png 1024w ,https://headtilt.me/media/posts/77/responsive/2_sentiment_samples-xl.png 1360w ,https://headtilt.me/media/posts/77/responsive/2_sentiment_samples-2xl.png 1600w ,https://headtilt.me/media/posts/77/responsive/2_sentiment_samples-sm2.png 375w" data-sizes="auto" height="310" width="836" alt="" class="lazyload blur-up"></div><div class="post__entry"><p>In 2019 I started up a programming-oriented Data Science class with my Year 10s. I ran two classes during the year, each spanning a semester. My aim for the course was to introduce students to different ways of storing, retrieving, and working with data, as well as give some coverage over different types of data and some operations that you can perform with it (e.g. numeric, text, spatial).</p><p>I ran a different main project with each class: during the first semester I looked at analysing data from the <a href="https://www.aph.gov.au/Parliamentary_Business/Hansard">Australian Federal Government Hansard</a>. Unfortunately, the students in the group weren't very interested in it, and (like many of my first time projects) the scope turned out to be overly broad, meaning students had trouble figuring out what they <em>would</em> do from all the alternatives of what they <em>could</em> do. Tangentially, working with the XML from the Hansard is a great (or terrible, depending on your perspective) activity in data cleaning - they've made some... interesting decisions about how to format their data inside the XML structure.</p><figure class="post__image post__image--center"><img class="lazyload blur-up" loading="lazy" src="https://headtilt.me/media/posts/77/responsive/1_hansard_snip-xs.png" data-sizes="auto" data-srcset="https://headtilt.me/media/posts/77/responsive/1_hansard_snip-xs.png 300w ,https://headtilt.me/media/posts/77/responsive/1_hansard_snip-sm.png 480w ,https://headtilt.me/media/posts/77/responsive/1_hansard_snip-md.png 768w ,https://headtilt.me/media/posts/77/responsive/1_hansard_snip-lg.png 1024w" alt="" width="2160" height="828"></figure><p>The second project was processing text to determine sentiment. This worked a lot better, and the project had a nice natural flow from the basic concepts of <a href="https://en.wikipedia.org/wiki/Lexical_analysis#Tokenization">tokenisation</a> and weighting, to some concepts like <a href="https://en.wikipedia.org/wiki/Stop_words">stop words</a>, before throwing in some (large) real world data sets to test out our algorithm. It's worthwhile noting here that it is <em>very</em> naive, and only gauges positive or negative sentiment, with no other categorisation like angry, sad, etc.</p><h2>Progression of Sentiment Analysis</h2><figure class="post__image post__image--right"><img class="lazyload blur-up" loading="lazy" src="https://headtilt.me/media/posts/77/responsive/2_sentiment_samples-xs.png" data-sizes="auto" data-srcset="https://headtilt.me/media/posts/77/responsive/2_sentiment_samples-xs.png 300w ,https://headtilt.me/media/posts/77/responsive/2_sentiment_samples-sm.png 480w ,https://headtilt.me/media/posts/77/responsive/2_sentiment_samples-md.png 768w ,https://headtilt.me/media/posts/77/responsive/2_sentiment_samples-lg.png 1024w" alt="" width="836" height="310"></figure>We start out by looking at some very basic examples and developing an algorithm. This might be some identification of simple tokens, or to start with just ordering the sentences from most positive to most negative and articulating what differentiates each sentence from its neighbours.<p></p><p>During the ranking process it becomes apparent that not all sentiment tokens are created equal, and so some sort of weighting system should come into play, meaning we can develop a scoring algorithm which we can apply to each sentence. I threw in a couple of ambiguous cases so that we also had to think about things like modifier words and symbols (e.g. 'not' coming before a sentiment token, shouty caps, or exclamation marks). </p><p>This is where we can start bringing in how to tackle programming the algorithm and process the simple sentences to see how it fares and whether or not the results match our expectations discussed at the start of the project. This is as simple as initialising a score variable, splitting the sentence on spaces, and normalising by stripping punctuation and changing to a standard case (typically lower). We can then examine each word, checking for membership in our lists of sentiment tokens (in class we grouped them to <strong>v_bad</strong>, <strong>bad</strong>, <strong>good</strong>, and <strong>v_good</strong> with anything not being in these lists not contributing to the score.</p><p>This worked pretty well with the sample sentences, but it was obvious that it did not deal with modifiers at all, so "not good" was counted as a positive sentiment in the same way that "good" was. In the previous code snippet, the enumerate function was used to get the position of each word in the sentence along with the word itself, so that we could examine the preceding word as well. This had the added benefit of being able to check for amplifying words like "very" at the same time. Modifying or inverting was simply a case of adding to, subtracting from, or multiplying (e.g. x2 for a boost, or x -1 for an inversion) the score for the current word.</p><p>From here we looked at the importance of stop words. For example our modifier words were sometimes separated by stop words, such as in one of the examples "but <strong>not</strong> in a <strong>good</strong> way". Filtering out any stop words prior to analysis and weighting made it possible to invert or amplify words which were not next to each other, but still related. This list of stop words we used can be found here: <a href="http://xpo6.com/list-of-english-stop-words/">http://xpo6.com/list-of-english-stop-words/</a></p><pre class="line-numbers" style="white-space: pre-wrap;" data-src="https://headtilt.me/media/files/10_sentiment_basic.py"> </pre><p class="msg msg--highlight"> An extract of the code showing the implementation of the scoring algorithm.</p><p>Once we played with the values to get to the point where we were happy with the (somewhat arbitrary) scores, all that was left to do was try it out with some real world data.</p><p>The <a href="http://mpqa.cs.pitt.edu">University of Pittsburgh Mult-Question Perspective Answering</a> site has a few interesting sets of data for download, and we grabbed a copy of the <a href="http://mpqa.cs.pitt.edu/lexicons/subj_lexicon/">Subjectivity Lexicon</a> (which is available for free, but you need to supply contact details), and split it up for use in our program. This gave use a huge list of words, along with a strong or weak associate with positive or negative use (and more practice splitting strings in Python :).</p><pre class="line-numbers" style="white-space: pre-wrap;" data-src="https://headtilt.me/media/files/10_sentiment_words.txt"> </pre><p class="msg msg--highlight"> A sample of the University of Pittsburgh data. We only used the <strong>type</strong>, <strong>word1</strong>, and <strong>priorpolarity</strong> key value pairs.</p><p class="msg msg--info">In retrospect one of their other data sets might have been more suitable, but this was the one I found initially and didn't bother exploring the others since it seemed good enough in the time I had available to investigate.</p><p>Lastly we needed some real world data which we could use to compare our results, and to stop using our toy data set of contrived sentences. Since the initial premise for the program was analysis of product reviews, what better place to look than Amazon. I found a set of <a href="https://nijianmo.github.io/amazon/index.html">Amazon reviews that had been collected</a> for analysis by Jianmo Ni from the University of California San Diego. Unlike the previous sets of data, this was nicely formatted as JSON, and there was a large range of different review categories, all of which were suitably huge (definitely from a student perspective, used to dealing with tens of data points). As the smallest set was more than enough for our purposes, I chose the Amazon Instant Video category, weighing in at a mere 37126 entries.</p><pre class="line-numbers" style="white-space: pre-wrap;" data-src="https://headtilt.me/media/files/10_sentiment_amazon.json"> </pre><p class="msg msg--highlight"> A sample of the Amazon Instant Video data. "<strong>overall</strong>" gives the star rating, and we also looked at the "<strong>reviewText</strong>" field. It would be interesting to see how useful the "<strong>helpful</strong>" data was in the future too.</p><p> Working with JSON let us look at working with libraries (although we had done some work with CSV prior to this) and the dictionary data structure.</p><p>One of the great things about this data set, is that whilst we could analyse the review text and see how our algorithm scored each one, each review also contained the star rating given by the reviewer, which meant that we could compare the implicit review sentiment based on the text to the explicit review rating and use this as a method for determining either the honesty of the review, or as a metric for evaluating the accuracy of our algorithm.</p><p>We ended up running out of time to do the final analysis, but I'll manage our time better next time I run with this project. Here's a quick program containing the work we did in class that I put together to look at accuracy, comparing the extremes of sentiment scores to star ratings, which turned out to be 73% accurate. Not too bad for a toy program that simplifies the problem quite a lot.</p><h2>What worked and what didn't</h2><p>As far as engagement goes, I think this worked really well - students followed the flow most of the way and I think the complexity of the main ideas were about right. Splitting, scoring, stop words, iterating through a list of words: all of these worked out fine.</p><p>Where things tended to fall apart a bit is when we got to importing the larger files. Even though the sentiment words and the JSON reviews were quite simple as individual entries, somehow the idea of processing tens of thousands of them was a bit intimidating.</p><figure class="post__image post__image--center"><img class="lazyload blur-up" loading="lazy" src="https://headtilt.me/media/posts/77/responsive/sentiment_tweet-xs.png" data-sizes="auto" data-srcset="https://headtilt.me/media/posts/77/responsive/sentiment_tweet-xs.png 300w ,https://headtilt.me/media/posts/77/responsive/sentiment_tweet-sm.png 480w ,https://headtilt.me/media/posts/77/responsive/sentiment_tweet-md.png 768w ,https://headtilt.me/media/posts/77/responsive/sentiment_tweet-lg.png 1024w" alt="" width="587" height="216"></figure>I was originally going to do an activity looking at identifying online chat behaviour, being inspired by <a href="https://twitter.com/DigTecInstitute/status/1163971165527785472">this tweet</a> from <a href="https://twitter.com/kkschulz">Karsten Schulz</a> (although taking a different approach). I ended up being put of by the difficulty of finding good sample data to work with that was real world but fairly tame. I might have another crack at it later on and maybe incorporate it into an IRC bot or something similar.<p></p><h2>Some final code</h2><p>Although we ran out of time in class, I put together a bit of code which compares Amazon review star ratings with calculated sentiment and tries to figure out how accurate the simple scoring algorithm is. It isn't quite finished, but I doubt that will change for a while.</p><pre class="line-numbers" style="white-space: pre-wrap;" data-src="https://headtilt.me/media/files/10_sentiment_final.py"> </pre></div><footer class="post__footer"><div class="post__last-updated">This article was updated on December 30, 2019</div><div class="post__footer__col"><ul class="post__tag"><li><a href="https://headtilt.me/wag/classroom/">classroom</a></li><li><a href="https://headtilt.me/wag/compsci/">compsci</a></li><li><a href="https://headtilt.me/wag/datascience/">datascience</a></li></ul></div><nav class="post__nav"><div class="post__nav__prev">Previous Post<h5><a href="https://headtilt.me/microbit-robotics-review-2019/" class="inverse" rel="prev">Micro:bit Robotics Review 2019</a></h5></div><div class="post__nav__next">Next Post<h5><a href="https://headtilt.me/robotics-showcase-epidemic/" class="inverse" rel="next">Micro:bit Epidemic</a></h5></div></nav></footer></article></main><footer class="footer"><div class="footer__copyright">Powered by inertia.</div><div class="footer__social"><a href="https://twitter.com/robpoulter" aria-label="Twitter"><svg class="icon"><use xlink:href="https://headtilt.me/assets/svg/svg-map.svg#twitter"/></svg></a></div></footer></div><script defer="defer" src="https://code.jquery.com/jquery-3.2.1.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script><script defer="defer" src="https://headtilt.me/assets/js/scripts.min.js?v=f503b0ac46db9f99180b3b9f932c7f9a"></script><script>(function() {
    		var script = document.createElement('script');
    		window.counter = 'https://headtilt_me.goatcounter.com/count'
    		script.async = 1;
    		script.src = '//gc.zgo.at/count.js';
    
    		var ins = document.getElementsByTagName('script')[0];
    		ins.parentNode.insertBefore(script, ins)
    	})();</script><script defer="defer" src="https://headtilt.me/assets/js/prism.js?v=afcf02720f838e992a12336758017bcf"></script></body></html>